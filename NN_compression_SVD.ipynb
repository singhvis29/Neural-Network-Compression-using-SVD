{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_A3_Problem1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwob1U0zmuQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "a823c56b-c2df-4cc8-8c01-fd3a6d658010"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow  as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.contrib.layers import fully_connected\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import cm\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvj3zWHrm1VB",
        "colab_type": "code",
        "outputId": "70754e61-7b94-483d-9cbc-20f006aa06c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "#Loading Dataset\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
        "\n",
        "#Number of hidden layers\n",
        "n_hl = 5\n",
        "\n",
        "#Number of neurons in each layer = 1024\n",
        "n_nodes_hl = [1024]*n_hl\n",
        "\n",
        "#size of vector of each sample\n",
        "n_inputs = 28*28\n",
        "\n",
        "#Number of output classes\n",
        "n_class = 10"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-2bfaacaa0013>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh2zZFJym7Eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaring X, y placefolder for input and output\n",
        "X = tf.placeholder(tf.float32, [None, n_inputs], name=\"X\") \n",
        "y = tf.placeholder(tf.int64, [None,10], name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x76JFf0WY3o",
        "colab_type": "code",
        "outputId": "a0d225bd-ad87-405d-9cbf-982b5e4297f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "#Neural Network with specified hidden layers \n",
        "with tf.name_scope(\"dnn\"):\n",
        "  \n",
        "  hidden_layer = [0 for i in range(n_hl)]\n",
        "  \n",
        "  hidden_layer[0] = tf.layers.dense(X, n_nodes_hl[0], tf.nn.relu, name='hl1')\n",
        "    \n",
        "  for i in range(1,n_hl):\n",
        "    hl_name = 'hl'+str(i+1)\n",
        "    print(hl_name)\n",
        "    hidden_layer[i] = tf.layers.dense(hidden_layer[i-1],n_nodes_hl[i], tf.nn.relu, name=hl_name)\n",
        "  \n",
        "  last_hl = hidden_layer[-1]\n",
        "  \n",
        "  logits = tf.layers.dense(hidden_layer[-1], n_class, activation=None, name='output')\n",
        "  logits_sm = tf.nn.softmax(logits)  #softmax output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-27f1fd484b2b>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "hl2\n",
            "hl3\n",
            "hl4\n",
            "hl5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY9nS7o1ShH6",
        "colab_type": "code",
        "outputId": "e26fe3f3-b2c7-41eb-9776-176d8a45ff38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(logits)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"dnn/output/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykyWWuZ2WZ1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cross entropy\n",
        "with tf.name_scope(\"loss\"):\n",
        "  xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits)\n",
        "  loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hQD3l-RWeFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "  training_op = optimizer.minimize(loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-12DRJkWjis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "  correct = tf.equal(tf.argmax(logits,1), tf.argmax(y,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ3cQ4b5WoK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD2M6Ie8Wq1U",
        "colab_type": "code",
        "outputId": "d428517f-e78d-49e2-ebd1-d7bc654ccb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#Training the NN\n",
        "n_epochs = 101\n",
        "batch_size = 50\n",
        "weights = [0 for i in range(n_hl+1)]\n",
        "biases = [0 for i in range(n_hl+1)]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    for iteration in range(mnist.train.num_examples // batch_size):\n",
        "      X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "      #print(X_batch.shape)\n",
        "      sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
        "    acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y:mnist.test.labels})\n",
        "    if epoch % 10 == 0:\n",
        "      print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
        "      \n",
        "  save_path = saver.save(sess, \"./mnist_model.ckpt\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 1.0 Test accuracy: 0.966\n",
            "10 Train accuracy: 1.0 Test accuracy: 0.9777\n",
            "20 Train accuracy: 0.98 Test accuracy: 0.9758\n",
            "30 Train accuracy: 1.0 Test accuracy: 0.9841\n",
            "40 Train accuracy: 1.0 Test accuracy: 0.982\n",
            "50 Train accuracy: 1.0 Test accuracy: 0.9839\n",
            "60 Train accuracy: 1.0 Test accuracy: 0.9836\n",
            "70 Train accuracy: 0.98 Test accuracy: 0.9815\n",
            "80 Train accuracy: 1.0 Test accuracy: 0.9816\n",
            "90 Train accuracy: 1.0 Test accuracy: 0.9818\n",
            "100 Train accuracy: 1.0 Test accuracy: 0.9854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OLYuX8Wyfm",
        "colab_type": "code",
        "outputId": "74db1d45-5ac8-42fa-f056-e7382a350ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'hl1/kernel:0' shape=(784, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'hl1/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'hl2/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'hl2/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'hl3/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'hl3/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'hl4/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'hl4/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'hl5/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'hl5/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'output/kernel:0' shape=(1024, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'output/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np__wrkIHXFM",
        "colab_type": "code",
        "outputId": "02b8934d-8b11-44a7-e32f-c661e9584d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Outputting the weights and biases\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, \"./mnist_model.ckpt\")\n",
        "  weights[0] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'hl1/kernel:0'))\n",
        "  for l in range(1,n_hl):\n",
        "    layer_name = 'hl'+str(l+1)+'/kernel:0'\n",
        "    #print(layer_name)\n",
        "    weights[l] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, layer_name))\n",
        "  weights[5] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'output/kernel:0'))\n",
        "\n",
        "  biases[0] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'hl1/bias:0'))\n",
        "  for l in range(1,n_hl):\n",
        "    layer_name = 'hl'+str(l+1)+'/bias:0'\n",
        "    #print(layer_name)\n",
        "    biases[l] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, layer_name))\n",
        "  biases[5] = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'output/bias:0'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./mnist_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XewLUZxA2TaH",
        "colab_type": "code",
        "outputId": "0c664b4d-96e8-4592-f90a-6aaee0f43a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "weights[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.02256305, -0.04756363,  0.01568658, ...,  0.03672467,\n",
              "          0.04900185,  0.0196046 ],\n",
              "        [ 0.00972131,  0.03792369,  0.04423331, ..., -0.00421304,\n",
              "         -0.04831158, -0.02925314],\n",
              "        [ 0.04968909,  0.04003197, -0.03157269, ..., -0.02185892,\n",
              "          0.03120586,  0.00199647],\n",
              "        ...,\n",
              "        [-0.04404537,  0.00144889,  0.00549342, ..., -0.0272951 ,\n",
              "          0.00364791, -0.02948521],\n",
              "        [-0.04351641,  0.02487745,  0.00029998, ...,  0.04417834,\n",
              "          0.04857656, -0.02395961],\n",
              "        [ 0.03215345, -0.02691865, -0.03697591, ..., -0.01438579,\n",
              "          0.05096023,  0.04501759]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqqfKz2roLr-",
        "colab_type": "code",
        "outputId": "5f1b5c63-522b-443c-e4ac-a9635f7b2dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "biases[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.15123259, -0.16778518, -0.07526848, ..., -0.05836593,\n",
              "         0.2359232 , -0.01319878], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EiaohhMH8Ld",
        "colab_type": "code",
        "outputId": "7ac94488-8d8a-4aba-cbcf-2d857581e422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Checking accuracy for extracted weights\n",
        "def relu(x):\n",
        "  return np.maximum(x,0)\n",
        "\n",
        "layer0 = relu(mnist.test.images@weights[0]+biases[0])\n",
        "layer1 = relu(layer0@weights[1]+biases[1])\n",
        "layer2 = relu(layer1@weights[2]+biases[2])\n",
        "layer3 = relu(layer2@weights[3]+biases[3])\n",
        "layer4 = relu(layer3@weights[4]+biases[4])\n",
        "output = layer4@weights[5]+biases[5]\n",
        "\n",
        "correct = np.equal(np.argmax(output[0],1), np.argmax(mnist.test.labels,1))\n",
        "accuracy = np.mean(correct)\n",
        "  \n",
        "print('Accuracy:', accuracy)\n",
        "  \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmSFvsh4IUhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Singular value decomposition\n",
        "S = [0]*(n_hl)  #tensor of singular values\n",
        "U = [0]*(n_hl)  #tensor of left singular vectors\n",
        "Vt = [0]*(n_hl)  #tensor of right singular vectors\n",
        "\n",
        "for l in range(0,n_hl):\n",
        "  U[l], S[l], Vt[l] = np.linalg.svd(weights[l], full_matrices=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVQOlxFjIn2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining new weights\n",
        "new_weights = {}\n",
        "d_lengths = [10,20,50,100,200,784]\n",
        "for d in d_lengths:\n",
        "  name = 'svd'+str(d)\n",
        "  #new_weights[name] = [tf.matmul(U[l][0][:,0:d], tf.matmul(tf.linalg.diag(S[l][0][:d]),tf.transpose(V[l][0])[:d,:])) for l in range(0,n_hl)]\n",
        "  new_weights[name] = [np.dot(U[l][0][:,:d], np.dot(np.diag(S[l][0][:d]), Vt[l][0][:d,:])) for l in range(0,n_hl)]\n",
        "  new_weights[name].append(weights[-1][0])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obfbEnOqJnDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compressed NN\n",
        "\n",
        "def svd_nn_model(d):\n",
        "  layer = [0 for i in range(n_hl)]\n",
        "  #print(layer)\n",
        "  name = 'svd'+str(d)\n",
        "  layer[0] = mnist.test.images@new_weights[name][0]+biases[0]\n",
        "  layer[0] = relu(layer[0])\n",
        "  \n",
        "  for i in range(1,len(n_nodes_hl)):\n",
        "    layer[i] = layer[i-1]@new_weights[name][i]+biases[i]\n",
        "    layer[i] = relu(layer[i])\n",
        "    \n",
        "  logits = layer[-1]@new_weights[name][-1]+biases[-1]\n",
        "  #logits = tf.nn.softmax\n",
        "  \n",
        "  correct = np.equal(np.argmax(logits,1), np.argmax(mnist.test.labels,1))\n",
        "  accuracy = np.mean(correct)\n",
        "\n",
        "  \n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLumodmwKSAd",
        "colab_type": "code",
        "outputId": "e4d6470d-e04a-4371-aea3-2a31a7a2639b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "svd_nn_model(784)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2G5c4NONmNy",
        "colab_type": "code",
        "outputId": "8bfe7a8d-5da6-45b9-d00c-cefd4a4c3eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Accuracies for compressed NN\n",
        "for d in d_lengths:\n",
        "  print('Number of singular matrix elements:', d, ',Accuracy:',svd_nn_model(d))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of singular matrix elements: 10 ,Accuracy: 0.1018\n",
            "Number of singular matrix elements: 20 ,Accuracy: 0.169\n",
            "Number of singular matrix elements: 50 ,Accuracy: 0.8645\n",
            "Number of singular matrix elements: 100 ,Accuracy: 0.9801\n",
            "Number of singular matrix elements: 200 ,Accuracy: 0.9847\n",
            "Number of singular matrix elements: 784 ,Accuracy: 0.9854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Po2brutQAfa",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRkNMYYPIUZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining s,u,vt with 20 singular values\n",
        "u = [U[l][0][:,0:20] for l in range(n_hl)]\n",
        "s = [np.diag(S[l][0][:20]) for l in range(n_hl)]\n",
        "vt = [Vt[l][0][0:20,:] for l in range(n_hl)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE4pLU-QPM-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_bar = [s[l]@vt[l] for l in range(n_hl)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArXFOWbQ-TQq",
        "colab_type": "code",
        "outputId": "88e193f6-72da-47a2-d695-9de5fd3016bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Initial U, V_bar matrix\n",
        "#print('U',u[5][0:5])\n",
        "print('V_bar',v_bar[4][0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "V_bar [-0.43047875 -0.4459179  -0.7832403  ... -0.75471675 -0.5920078\n",
            " -0.5116921 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x7jmzaY4gNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "U_new = [tf.Variable(tf.convert_to_tensor(u[i])) for i in range(n_hl)]\n",
        "V_bar_new = [tf.Variable(tf.convert_to_tensor(v_bar[i])) for i in range(n_hl)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYN1ojizfZb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neural_network_model_w_svd_vars(data):\n",
        "  global U_new\n",
        "  global V_bar_new\n",
        "  \n",
        "  #Reconstructing the weights\n",
        "  weights_updated = [tf.matmul(U_new[i],V_bar_new[i]) for i in range(n_hl)]\n",
        "  \n",
        "  #Declaring weights and biases for each layer\n",
        "  hidden_layer = [0 for i in range(len(n_nodes_hl))]\n",
        "  hidden_layer[0] = {'weights':weights_updated[0],\n",
        "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl[0]]))}\n",
        "  \n",
        "  for i in range(1,len(n_nodes_hl)):\n",
        "      hidden_layer[i]={'weights':weights_updated[i],\n",
        "                       'biases':tf.random_normal([n_nodes_hl[i]])}\n",
        "      \n",
        "  output_layer = {'weights':weights[-1][0],\n",
        "                   'biases':tf.Variable(tf.random_normal([n_class]))}\n",
        "  \n",
        "  layer = [0 for i in range(len(n_nodes_hl))]\n",
        "  layer[0] = tf.add(tf.matmul(data, hidden_layer[0]['weights']), hidden_layer[0]['biases'])\n",
        "  layer[0] = tf.nn.relu(layer[0])\n",
        "  \n",
        "  for i in range(1,len(n_nodes_hl)):\n",
        "    layer[i] = tf.add(tf.matmul(layer[i-1], hidden_layer[i]['weights']), hidden_layer[i]['biases'])\n",
        "    layer[i] = tf.nn.relu(layer[i])\n",
        "    \n",
        "  output = tf.matmul(layer[-1], output_layer['weights']) + output_layer['biases']\n",
        "  \n",
        "  return output, U_new, V_bar_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLlCwzX5kBCC",
        "colab_type": "code",
        "outputId": "d6f5f79b-6cee-4c43-c2e1-bb6dfe82d237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training new model with U and V_bar\n",
        "prediction, u, v = neural_network_model_w_svd_vars(X)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
        "\n",
        "correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "\n",
        "hm_epochs = 101\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.initialize_all_variables())\n",
        "\n",
        "  for epoch in range(hm_epochs): \n",
        "    epoch_loss = 0\n",
        "    for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "      epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "      _, c = sess.run([optimizer, cost], feed_dict = {X: epoch_x, y: epoch_y})\n",
        "      epoch_loss += c\n",
        "    if epoch % 10 ==0:\n",
        "      print('Epoch',epoch, epoch_loss)\n",
        "      print('Train Accuracy:', accuracy.eval({X:epoch_x, y:epoch_y}))\n",
        "      print('Updated final set of V_bar',sess.run(v[4][0]))\n",
        "\n",
        "\n",
        "  print('Test Accuracy:', accuracy.eval({X:mnist.test.images, y:mnist.test.labels}))\n",
        "\n",
        "  save_path = saver.save(sess, \"./mnist_test_svd.ckpt\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-961981886087>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Epoch 0 526.1912607548293\n",
            "Train Accuracy: 0.94\n",
            "Updated final set of V_bar [-0.42805848 -0.4456998  -0.7839892  ... -0.7545684  -0.59197265\n",
            " -0.5156501 ]\n",
            "Epoch 10 38.22765079068108\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.44149658 -0.4623381  -0.7776793  ... -0.76162463 -0.60076696\n",
            " -0.5306485 ]\n",
            "Epoch 20 16.85299705095455\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.440174   -0.4632443  -0.7869192  ... -0.7697097  -0.59643143\n",
            " -0.5361204 ]\n",
            "Epoch 30 12.3217101872388\n",
            "Train Accuracy: 0.98\n",
            "Updated final set of V_bar [-0.43578255 -0.46919587 -0.79562014 ... -0.7599847  -0.58230764\n",
            " -0.5295787 ]\n",
            "Epoch 40 10.796517194537714\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.41113234 -0.4612933  -0.7985977  ... -0.6979633  -0.5788958\n",
            " -0.52593106]\n",
            "Epoch 50 3.6478671178242346\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.35250938 -0.4604272  -0.79890776 ... -0.6997847  -0.578654\n",
            " -0.519366  ]\n",
            "Epoch 60 1.8743646326981933\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.34188455 -0.45301273 -0.8038619  ... -0.70236534 -0.5596709\n",
            " -0.51014864]\n",
            "Epoch 70 8.804682049877947\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.34920418 -0.4435372  -0.8038997  ... -0.6981261  -0.5541086\n",
            " -0.51647854]\n",
            "Epoch 80 4.589856552622731\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.33202726 -0.44051516 -0.8040209  ... -0.68702555 -0.55112964\n",
            " -0.517335  ]\n",
            "Epoch 90 4.786915003598892\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.32600915 -0.43307805 -0.80100816 ... -0.68088615 -0.547363\n",
            " -0.5171979 ]\n",
            "Epoch 100 1.1610085500953318\n",
            "Train Accuracy: 1.0\n",
            "Updated final set of V_bar [-0.33658013 -0.42295745 -0.8012132  ... -0.670738   -0.5467817\n",
            " -0.519526  ]\n",
            "Test Accuracy: 0.9791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZz3zTjA-ig0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}